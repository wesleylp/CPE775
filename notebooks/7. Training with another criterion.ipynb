{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNNNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(CNNNet, self).__init__()\n",
    "        \n",
    "        self.output_shape = output_shape\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        C, W, H = input_shape\n",
    "        P, D = output_shape\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(C, 32, (3, 3), padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Conv2d(32, 64, (3, 3), padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Conv2d(64, 128, (3, 3), padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Conv2d(128, 256, (3, 3), padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(int(W/16*H/16*256), 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, P*D)\n",
    "        )\n",
    "        \n",
    "        self._weights_init()\n",
    "        \n",
    "    def _weights_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_normal(m.weight.data)\n",
    "\n",
    "    def forward(self, x):    \n",
    "        C, W, H = self.input_shape\n",
    "        P, D = self.output_shape\n",
    "        \n",
    "        x = self.features(x)\n",
    "        \n",
    "        x = x.view(-1, int(W/16*H/16*256))\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x.view(-1, P, D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset and splitting between train and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cpe775.dataset import FaceLandmarksDataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.transforms import Compose\n",
    "from cpe775.transforms import ToTensor, CropFace, ToGray, RandomHorizontalFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "random_seed = 42\n",
    "valid_size = 0.2\n",
    "shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_transforms = Compose([\n",
    "                   CropFace(enlarge_ratio=1.7),\n",
    "                   RandomHorizontalFlip(),\n",
    "                   ToGray(),\n",
    "                   ToTensor()\n",
    "                 ])\n",
    "\n",
    "transforms = Compose([\n",
    "                   CropFace(enlarge_ratio=1.7),\n",
    "                   ToGray(),\n",
    "                   ToTensor()\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "train_dataset = FaceLandmarksDataset(csv_file='../data/train.csv',\n",
    "                                     root_dir='../data/',\n",
    "                                     transform=train_transforms)\n",
    "valid_dataset = FaceLandmarksDataset(csv_file='../data/train.csv',\n",
    "                                     root_dir='../data/',\n",
    "                                     transform=transforms)\n",
    "\n",
    "num_train = len(train_dataset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "if shuffle == True:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                batch_size=batch_size, sampler=train_sampler, num_workers=4)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, \n",
    "                batch_size=batch_size, sampler=valid_sampler, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = CNNNet((1, 256, 256), (68, 2)) # input shape, output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = torch.nn.DataParallel(net)\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17200264"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([v.numel() for v in net.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from cpe775.criterion import RMSELoss\n",
    "from cpe775.model import Model\n",
    "from cpe775 import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), 0.01, momentum=0.9)\n",
    "model = Model(net, criterion=criterion)\n",
    "model.set_optimizer(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from cpe775 import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callback_list = [\n",
    "        callbacks.Progbar(print_freq=40),\n",
    "        callbacks.ModelCheckpoint('../results/cnnnet/checkpoint-lr-scheduler-mse-loss.pth.tar', 'val_loss', mode='min'),\n",
    "        callbacks.LearningRateScheduler(MultiStepLR(optimizer, milestones=[750,900], gamma=0.1))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch._C.mean>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/79]\tTime 2.756 (2.756)\tData 1.851 (1.851)\tTrain Loss 0.264 (0.264)\tTrain Rmse 2.084 (2.084)\t\n",
      "Epoch: [0][40/79]\tTime 0.749 (0.365)\tData 0.724 (0.298)\tTrain Loss 0.008 (0.131)\tTrain Rmse 0.338 (1.267)\t\n",
      "Val: [0/20]\tTime 1.524 (1.524)\tData 1.499 (1.499)\tVal Loss 0.002 (0.002)\tVal Rmse 0.170 (0.170)\t\n",
      "Epoch: [1][0/79]\tTime 1.669 (1.669)\tData 1.632 (1.632)\tTrain Loss 0.002 (0.002)\tTrain Rmse 0.167 (0.167)\t\n"
     ]
    }
   ],
   "source": [
    "model.fit_loader(train_loader, 1000, val_loader=valid_loader,\n",
    "                 callback=callbacks.Compose(callback_list), metrics={'rmse': RMSELoss()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(callback_list[1].history['train_loss'][5:])\n",
    "plt.plot(callback_list[1].history['val_loss'][5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('../results/cnnnet/checkpoint-lr-scheduler-mse-loss.pth-best.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cpe775.utils.img_utils import show_landmarks_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = Model(CNNNet((1, 256, 256), (68, 2)))\n",
    "best_net = model.net\n",
    "best_net.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch, sample_batched in enumerate(valid_loader):\n",
    "    \n",
    "    predicted_landmarks = best_net(torch.autograd.Variable(sample_batched['image'], volatile=False)).cpu().data\n",
    "    plt.figure(figsize=(20,6))\n",
    "    show_landmarks_batch({'image': sample_batched['image'], 'landmarks': predicted_landmarks})\n",
    "    plt.axis('off')\n",
    "    plt.ioff()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = FaceLandmarksDataset(csv_file='../data/common_test.csv',\n",
    "                               root_dir='../data/',\n",
    "                               transform=transforms)\n",
    "\n",
    "common_loader = torch.utils.data.DataLoader(dataset, \n",
    "                batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = 0\n",
    "for i_batch, sample_batched in enumerate(common_loader):\n",
    "    \n",
    "    predicted_landmarks = best_net(torch.autograd.Variable(sample_batched['image'], volatile=False)).cpu().data\n",
    "    \n",
    "    loss += predicted_landmarks.shape[0]*criterion(predicted_landmarks, sample_batched['landmarks'])\n",
    "    \n",
    "    plt.figure(figsize=(20,6))\n",
    "    show_landmarks_batch({'image': sample_batched['image'], 'landmarks': predicted_landmarks})\n",
    "    plt.axis('off')\n",
    "    plt.ioff()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss/len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenging test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "challenging_set = FaceLandmarksDataset(csv_file='../data/challenging_test.csv',\n",
    "                               root_dir='../data/',\n",
    "                               transform=transforms)\n",
    "\n",
    "challeging_loader = torch.utils.data.DataLoader(challenging_set, \n",
    "                batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = 0\n",
    "for i_batch, sample_batched in enumerate(challeging_loader):\n",
    "    \n",
    "    predicted_landmarks = best_net(torch.autograd.Variable(sample_batched['image'], volatile=False)).cpu().data\n",
    "    \n",
    "    loss += predicted_landmarks.shape[0]*criterion(predicted_landmarks, sample_batched['landmarks'])\n",
    "    \n",
    "    plt.figure(figsize=(20,6))\n",
    "    show_landmarks_batch({'image': sample_batched['image'], 'landmarks': predicted_landmarks})\n",
    "    plt.axis('off')\n",
    "    plt.ioff()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss/len(challenging_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
